import os
import random
import shutil

# Define input dataset path and output dataset path
input_dataset = '/home/Student/s4582342/data_old'
output_path = '/home/Student/s4582342/data'
output_train = os.path.join(output_path, 'train')
output_val = os.path.join(output_path, 'val')
output_test = os.path.join(output_path, 'test')

# Define new splits
new_split = {'train': 28200, 'val': 4500, 'test': 3800}

# Created new splits while maintaining class balance
# Generated by OpenAI's ChatGPT
def reduce_split_size(input_dir, output_dir, desired_size):
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    # List all videos in the input directory
    videos = os.listdir(input_dir)

    # Randomly shuffle the videos to ensure randomness
    random.shuffle(videos)

    # Calculate how many videos to keep from this split
    num_to_keep = min(len(videos), desired_size)

    # Select the first `num_to_keep` videos
    selected_videos = videos[:num_to_keep]

    # Copy the selected videos to the output directory
    for video in selected_videos:
        video_path = os.path.join(input_dir, video)
        output_path = os.path.join(output_dir, video)
        shutil.copyfile(video_path, output_path)

# Run function for each split
reduce_split_size(os.path.join(input_dataset, 'train'), output_train, new_split['train'])
reduce_split_size(os.path.join(input_dataset, 'val'), output_val, new_split['val'])
reduce_split_size(os.path.join(input_dataset, 'test'), output_test, new_split['test'])
